<!DOCTYPE html>
<html lang="en-us">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, height=device-height, initial-scale=1">
<link rel="stylesheet" href="/tachyons.min.css">
<link rel="stylesheet" href="/style.css">
<title>Peter Jin</title>
</head>
<body>
<div id="container">
<div id="header">
<div class="fl">
<h1><a href="/">Peter Jin</a></h1>
</div>
<div class="fr">
<span class="rhs sans-serif"><a href="/#notes">Notes</a></span>
<span class="rhs sans-serif"><a href="/#contact">Contact</a></span>
</div>
<div class="cb-ns"></div>
</div>
<div id="contentwraptop"></div>
<div id="contentwrap">
<div id="content">
<div>

<h2>An exact parser from natural language math into logical forms</h2>
<br><br>
May 7, 2024
<em>(last updated May 29, 2024)</em>
<br><br>

The task considered in this note is the following.
Given a natural language math sentence, e.g.:
<br><br>

&ldquo;Let $ABC$ be an acute triangle with circumcenter $O$. [&hellip;]
Prove that line $AO$ meets $BC$ at $X$.&rdquo;
<br><br>

parse it into <a href="/notes/loglang.html">logical forms</a>,
e.g.:
<br><br>

<pre>
$ABC$ <- "triangle"().
"acute"($ABC$).
$O$ <- "circumcenter"($ABC$).
-- [...]
$AO$ <- "line"().
prove ( "meet"($AO$, $BC$) -> $X$ ).
</pre>
<br>

The logical forms corresponding to the natural language
math can then be fed as input into, e.g.,
<a href="/notes/exp.html">a forward-chaining prover</a>
such as
<a href="https://github.com/peterhj/meringue">Meringue</a>.
(The task of parsing natural language into logical forms has
also been called <em>semantic</em> parsing
[<a href="#L16">L16</a>], but we simply call it parsing,
hopefully without loss of clarity.)
<br><br>

Note that, depending on the complexity or size of the
logical form domain, LLMs of various sizes can already do
this task to an extent, either few-shot as a general base or
instruction-tuned model, or with task-specific fine-tuning.
<br><br>

As to why one might <em>not</em> use an LLM for this task,
such a question gets into the current limitations of LLMs
for reasoning in general.
<br><br>

First, let us note that LLMs may be considered artificial
<em>general</em> intelligence in the sense that they have
generalization capabilities and general knowledge across
many tasks and domains.
In the space of tasks and domains, LLMs can be said to
possess super-human <em>recall</em>
(i.e. lower proportion of false negatives).
However, it is also empirically observed that LLMs are
often wrong (e.g. hallucination, false reasoning).
It is in the latter sense that LLMs can also be said to
possess sub-par <em>precision</em>
(i.e. more false positives than desired or expected).
<br><br>

Thus, an alternative to LLMs may prefer to focus more on
precision (fewer false positives) at the cost of recall
(i.e. a narrower domain).
<br><br>

A second consideration relates to the inference throughput
of LLMs.
Single-GPU inference throughput of LLMs is typically around
100-1000 token/s, or 1-10 ms/token
(to the nearest order of magnitude)
for a single stream of tokens;
batched inference can bring the number to around
1000-10000 token/s, or 0.1-1 ms/token
[<a href="#N24" style="cite">N24</a>].
<br><br>

With the above considerations in mind, a prototype exact
parser from natural language mathematics into logical forms
was implemented by hand.
The prototype implementation is
<a href="https://github.com/peterhj/praline">on GitHub</a>.
<br><br>

The &ldquo;minimum description length&rdquo; of the parser
is rather long, and so a pseudocode description of the
algorithm does not really elucidate how it works.
However, some high level remarks may be informative.
<br><br>

<h3>Cooperative backtracking parser architecture</h3>
<br><br>

The parsing algorithm itself is best thought of as a
handful of <em>cooperating phases</em> that operate on a
<em>shared backtracking stack</em>.
During a parse, the cooperating phases alternate,
each phase committing an operation (or,
<em>choice point</em>) on the shared backtracking stack.
A parse failure that arises during any of the phases
causes backtracking of the stack in depth-first-search
order.
<br><br>

In the current version of the parser, the cooperating
phases are:
(1) lexical segmentation,
(2) lexical tree adjoining,
and (3) syntactic tree building.
(The algorithm has a strong resemblance to Pratt parsing
[<a href="#P73" class="cite">P73</a>],
which was explicitly an inspiration.)
<br><br>

Lexical segmentation looks ahead in the input text
character stream and determines the next
<em>lexical item</em> (essentially a token).
Lexical segmentation also assigns the lexical item
a <em>logical kind</em>, which is analogous to a
&ldquo;part-of-speech.&rdquo;
<br><br>

Lexical tree adjoining takes the current lexical item
and determines which earlier lexical item is a suitable
destination as either a parent or a left-sibling in the
<em>lexical tree</em>.
There are often multiple possible adjoining destinations,
in which case they should be ordered from most likely to
least.
<br><br>

Syntactic tree building transforms the lexical tree into
a <em>syntactic tree</em>
(i.e. an AST of the logical form language).
This is done bottom-up and incrementally upon the
adjoining of the current lexical item.
This phase has the most complex implementation, though
it looks like just a bunch of nested lookup tables.
<br><br>

All three cooperating phases can independently
<em>fail</em> and <em>backtrack</em> using the shared
backtracking stack.
<br><br>

During lexical segmentation,
the next lexical item may be too long, when instead
a string prefix of the item should have been segmented.
The assigned logical kind may also cause failure.
<br><br>

During lexical tree adjoining,
if the current lexical item were adjoined to the wrong
parent or left-sibling,
then the next possible adjoining destination would be
tried after backtracking.
Pairwise comparisons of the lexical items&rsquo;
logical kinds are sometimes sufficient to catch what
would be an erroneous parse, and to instead fail early.
<br><br>

Finally, during syntactic tree building,
a typical failure is a missing case in one of the
lookup tables.
The missing case could simply be an implementation
issue, which is manually fixed by adding the relevant
case handling code,
but could also be an outright erroneous case.
<br><br>

<h3>Parser improvement as imitation learning</h3>
<br><br>

The strategy by which the parser was written was
essentially a form of <em>test-driven development</em>,
in which test coverage was measured on a dataset of
transcribed IMO shortlist geometry problems.
Thus, the parser was incrementally implemented by making
small modifications and refactorings to parse new test
cases in the dataset.
However, we can formulate the process of
<em>parser improvement</em> much more rigorously.
<br><br>

Let us consider the process of parser improvement as a
<em>learning</em> process.
We are given a training dataset consisting of pairs
<code>(String, () -> Tree)</code>.
The first element of a training pair is a natural language
math sentence, e.g. from a corpus of olympiad math problems.
The second element is a <em>lazy label</em> and is a closure
returning the logical form abstract syntax tree (AST)
corresponding to the first natural language math sentence.
In other words, the learning process is an instance of
<em>lazy supervised learning</em>;
while training examples need labels, they do not need to be
pre-labeled up front.
<br><br>

Formally, a <em>parser</em> is a function:
<br><br>
<pre>
Parse : String -> Success(Tree)|Failure(ParseState)
</pre>
<br>
where <code>Success(_)|Failure(_)</code> is the notation
for a direct sum type (a.k.a. ADT or enum).
<br><br>

Now, suppose that the current parser produces a failed
parse, i.e. <code>Failure(ParseState)</code>.
We can inspect the <code>ParseState</code> to learn more
about the parse failure and how to possibly modify the
parser to avoid failure.
Because our parsing architecture is based on a shared
backtracking stack,
it is possible to inspect the backtracking history and to
find the <em>longest prefix</em> of the input string that
yielded an incremental parse before encountering parse
failure.
More generally, the tree-structured backtracking history
of the <code>ParseState</code> allows one to observe the
sequence of actual parsing choice points, and to guess at
which counterfactual parsing choices could have led to
parsing success.
<br><br>

The availability of the longest prefix also allows one to
define an <em>ordering</em> on the training dataset.
For each training sample that does not yet successfully
parse, calculate the longest prefix among its incremental
parses, and take the ratio of the longest prefix length to
the input string length.
Sorting the training samples by decreasing ratio, one
attains a <em>lowest-hanging-fruit ordering</em>,
where the training samples at the front are closest to
being successfully parsed.
Thus, efforts to improve the parser should focus on those
training samples first.
<br><br>

The reasoning above leads us to the following meta-algorithm
for parser improvement:
<br><br>

<pre>
initialize regression set = empty set
while training is not done:
    choose a training pair (x, y) by the lowest-hanging-fruit ordering
    evaluate the label t of x
    -- i.e., t is the target logical form tree
    if y is a successful parse:
        if y is compatible with t:
            add (x, y) to the regression set
            continue
    while True:
        modify the parser in a small but promising direction
        run the modified parser on x to get a new parse y'
        if y' is a failed parse:
            continue
        if y' is not compatible with t:
            continue
        run the parser on the regression set
        if there are any parsing regressions:
            continue
        break
    add (x, y') to the regression set
</pre>
<br>

Let us briefly analyze the parse improvement meta-algorithm.
<br><br>

1. Parser improvement is formally related to imitation
learning algorithms,
e.g. DAgger [<a href="#RG11" style="cite">RG11</a>].
<br><br>

2. As parser improvement involves running the parser on the
entire regression set, then its feasibility requires a fast
parser.
<br><br>

3. While the initial implementation of parser improvement is
based on a human expert evaluating target logical form tree
labels and modifying the parser,
in theory those two tasks could be partially augmented
(or even entirely substituted) by an AI system
(e.g. a system based on LLMs),
enabling the possible scaling up of parser improvement.
<br><br>

<h3>Results on an IMO dataset</h3>
<br><br>

The actual training dataset consists of 135 IMO shortlist
geometry problems from 2006 to 2022,
from which we extracted 578 English (LaTeX) sentences of
natural language mathematics.
Target logical forms corresponding to those sentences were
supplied, lazily, by the author.
In practice, fresh parses from the parser itself were also
accepted in lieu of the author explicitly deriving a target
logical from tree from scratch;
this could be considered <em>doubly lazy</em> supervision.
<br><br>

In its current state, the
<a href="https://github.com/peterhj/praline">Praline</a>,
parser produces
121 gold parses out of 578 total samples,
for a training recall of 21%.
The training precision is, roughly, 100%,
with the caveat that the human expert may not have perfectly
labeled every training sample.
<br><br>

Typical &ldquo;inference throughput&rdquo; of the parser
is about 0.1-1 ms/sentence,
or equivalently around 0.01-0.1 ms/token,
to the nearest order of magnitude.
<br><br>

What about the performance impact of backtracking?
Among the 121 gold parses, the median backtrack count is 45,
the mean 56, the minimum 20, and the maximum 165.
These numbers suggest that even simple depth-first
backtracking is not too expensive on natural language
sentences.
<br><br>

The bulk of the development of the parser occurred over an
approximately 8-week period.
The first half was spent iterating on the parser
architecture and practicing the parser improvement process
on each iteration.
During the second half, the parsing architecture was frozen
on the cooperating backtracking architecture described
earlier, and parser improvement proceeded in earnest.
<br><br>

<h3>Acknowledgments</h3>
<br><br>

We thank David Shin for helpful discussions and feedback.
<br><br>

<h3>References</h3>
<br><br>

<span id="L16">[L16]
Percy Liang.
&ldquo;Learning Executable Semantic Parsers for Natural Language Understanding.&rdquo;
<em>Communications of the ACM</em> 59(9), pp. 68-76 (2016).
</span>
<br><br>

<span id="N24">[N24]
Nvidia.
&ldquo;H200 achieves nearly 12,000 tokens/sec on Llama2-13B with TensorRT-LLM.&rdquo;
URL: <a href="https://nvidia.github.io/TensorRT-LLM/blogs/H200launch.html">https://nvidia.github.io/TensorRT-LLM/blogs/H200launch.html</a> (2024).
</span>
<br><br>

<span id="P73">[P73]
Vaughan R. Pratt.
&ldquo;Top down operator precedence.&rdquo;
In <em>Proceedings of the 1st Annual ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages</em> (1973).
</span>
<br><br>

<span id="R11">[R11]
St&eacute;phane Ross, Geoffrey J. Gordon, and J. Andrew Bagnell.
&ldquo;A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning.&rdquo;
In <em>Proceedings of the 14th International Conference on Artificial Intelligence and Statistics (AISTATS 2011)</em>.
</span>

</div>
</div><!--#content-->
</div><!--#contentwrap-->
<div id="contentwrapbot"></div>
</div><!--#container-->
</body>
</html>
