<!DOCTYPE html>
<html lang="en-us">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, height=device-height, initial-scale=1">
<link rel="stylesheet" href="/tachyons.min.css">
<link rel="stylesheet" href="/style.css">
<title>Peter Jin</title>
</head>
<body>
<div id="container">
<div id="header">
<div class="fl">
<h1><a href="/">Peter Jin</a></h1>
</div>
<div class="fr">
<span class="rhs sans-serif"><a href="/#notes">Notes</a></span>
<span class="rhs sans-serif"><a href="/#contact">Contact</a></span>
</div>
<div class="cb-ns"></div>
</div>
<div id="contentwraptop"></div>
<div id="contentwrap">
<div id="content">
<div>

<h2>An exploratory improvement operator for a forward-chaining prover</h2>
<br><br>
May 7, 2024
<em>(last updated May 9, 2024)</em>
<br><br>

<h3>Background: forward-chaining theorem proving with choice</h3>
<br><br>

The following is a basic sketch of a forward-chaining
theorem prover with choice:
<br><br>

<pre>
in the primary logical context, given:
    a set of logical rules
    a set of logical propositions
    a set of logical goals
while True:
    compute the fixed-point saturation of the non-choice logical rules
    update the primary logical context with the fixed-point computation
    for every logical rule choice:
        create a working copy of the primary logical context
        in the working logical context:
            evaluate the effect of applying the choice
        record the evaluated effect
    select the logical rule choice that has the best effect
    apply the selected choice (in the primary logical context)
    if a logical contradiction was reached:
        raise a logical exception
    if all logical goals are satisfied:
        break
</pre>
<br>

Above, by non-choice and choice logical rules, we refer
to the
<a href="/notes/loglang.html">previous note on logical languages</a>.
<br><br>

Forward-chaining theorem provers for geometry solving
will often refer to the above forward-chaining sketch as
a <em>deductive database</em>,
where the choices are restricted to logical rules that
produce geometric constructions
[<a href="#CG00" class="cite">CG00</a>].
<br><br>

For our purposes, the key design decision is how to
evaluate the effect of making a logical choice.
The next section will describe such a design.
(For a practical implementation, please see
<a href="https://github.com/peterhj/meringue">Meringue</a>.)
<br><br>

<h3>Logical inference, partial evaluation, and intrinsic visit counts</h3>
<br><br>

Let us proceed with an example.
Consider two logical rules as follows:
<br><br>

<pre>
axm for x, y { a(x), b(x, y), c(y) -: e(x, y) }
axm for x, y { a(x), d(x, y), c(y) -: f(x, y) }
</pre>
<br>

The two primal logical rules above induce several
<em>auxiliary</em> logical rules that should be added
to the full set of logical rules evaluated during
fixed-point saturation.
One set of auxiliary rules are essentially identities:
<br><br>

<pre>
axm for x { a(x) -: a'(x) }
axm for x { c(x) -: c'(x) }
axm for x, y { e(x, y) -: e'(x, y) }
axm for x, y { f(x, y) -: f'(x, y) }
axm for x, y { a(x), b(x, y), c(y) -: abc'(x, y) }
axm for x, y { a(x), d(x, y), c(y) -: adc'(x, y) }
</pre>
<br>

where relations <code>a'</code>, etc. are automatically
defined as auxiliary relations.
<br><br>

Another set of auxiliary rules consist of all the
non-trivial partially evaluated joins of the primal
logical rules:
<br><br>

<pre>
axm for x, y { a(x), c(y) -: ac'(x, y) }
axm for x, y { a(x), b(x, y) -: ab'(x, y) }
axm for x, y { c(x), b(x, y) -: cb'(x, y) }
axm for x, y { a(x), d(x, y) -: ad'(x, y) }
axm for x, y { c(x), d(x, y) -: cd'(x, y) }
</pre>
<br>

For logical rules that produce functional tuples or
(in)equalities (i.e. unification),
there are corresponding auxiliary logical rules that
are triggered by the relevant unifications.
<br><br>

These auxiliary logical rules then directly induce
an intrinsically motivated metric of the progress made
on partial rule evaluation during logical inference.
Specifically, when evaluating a logical rule choice,
each produced logical tuple corresponding to an auxiliary
relation (except for the tuple corresponding to the
choice itself, on which the evaluation is conditioned)
then increments a <em>visit count</em> specific to that
auxiliary relation.
Logical tuples are produced during fixed-point saturation
(including both the primal and auxiliary logical rules),
and the evaluation with choice may be done recursively.
<br><br>

The selection phase looks at the minimum of all auxiliary
visit counts that were updated during the last evaluation,
and selects the choice with least min-updated-visit-count.
(Choices that do not cause any visit count updates
are considered to have infinite min-updated-visit-count.)
In practice, the min-updated-visit-count selection rule is
augmented with a noise mechanism, akin to epsilon-greedy
policies used in reinforcement learning.
<br><br>

At a higher level, the use of auxiliary visit counts
induced by auxiliary relations and auxiliary logical rules
may be more simply seen as a sufficient implementation of
an <em>exploration</em>-based <em>improvement operator</em>
for a general forward-chaining prover.
That is, the improvement operator takes the state of the
forward-chaining prover (i.e. its logical context),
and returns a new prover state with fresh logical tuples
produced by inference of logical rules, all in bounded
space and time.
<br><br>

<h3>Implementation details</h3>
<br><br>

Let us briefly discuss a couple of implementation details.
<br><br>

One is how to implement the (parallel) evaluation of choices.
Two possible decisions here are copy-on-write and
reversible data structures/algorithms.
<a href="https://github.com/peterhj/meringue">Meringue</a>
uses a copy-on-write prover context dispatched per
thread-worker,
which greatly simplifies the initial prototyping.
As the copy-on-write implementation currently uses
atomics and persistent data structures,
an alternative implementation based on reversibility
(e.g. via an <code>undo</code> operation implemented
on the prover context, and each thread-worker maintaining
a thread-local persistent context)
is expected to be more performant, but as reversibility is
a very &ldquo;leaky abstraction,&rdquo;
so its implementation is not to be taken lightly.
<br><br>

A second is how to implement the evaluation of logical
rules.
<a href="https://github.com/peterhj/meringue">Meringue</a>
evaluates one-logical-rule-at-a-time,
and uses <em>worst-case-optimal joins</em>
[<a href="#NP12" class="cite">NP12</a>,
<a href="#V12" class="cite">V12</a>]
to evaluate individual logical rules;
no geometry-specific logic is involved in the evaluation
implementation.
There is potentially some low-hanging fruit for speeding
up general forward-chaining evaluation.
<br><br>

<h3>Forward- v. backward-chaining</h3>
<br><br>

While the discussion in this note is focused on
forward-chaining (i.e. fixed-point-based) theorem provers,
one may also consider how backward-chaining
(i.e. backtracking/depth-first-search-based) provers fit
into the overall picture.
(Prolog is the classic example of a backward-chaining
prover.)
<br><br>

The &ldquo;inner loop&rdquo; of forward-chaining is
usually a <em>join</em> computation implemented by a
backtracking/DFS-based algorithm very similar to
that of backward-chaining.
However, there are two differences.
First, forward-chaining then wraps an embarassingly
parallel &ldquo;outer loop&rdquo; around many independent
inner loop joins.
(The analog of &ldquo;outer loop&rdquo;-parallelization
for backward-chaining is called <em>or-parallelism</em>,
which considers disjunctive hypothetical <em>branches</em>
in parallel;
however, forward-chaining is expected to be easier to
parallelize than backward-chaining.)
Second, the backtracking/DFS implementation of a
worst-case-optimal join, as used in forward-chaining,
will make different tradeoffs and optimizations compared
to the implementation as used in backward-chaining.
<br><br>

Backward-chaining is useful for goal and subgoal
decomposition via the backtracking/DFS stack order,
which is formally complementary to the forward-chaining
approach that takes goals/subgoals as given.
Hybrid forward/backward-chaining approaches (that use
backward-chaining to construct goals and subgoals, and
forward-chaining to search from assumptions toward
goals/subgoals) are an underexplored subject.
<br><br>

<h3>Comparison with AlphaGeometry (DD+AR)</h3>
<br><br>

<a href="https://github.com/google-deepmind/alphageometry">AlphaGeometry</a>
[<a href="#TW24" class="cite">TW24</a>]
consists of (1) a symbolic geometry solver, DD+AR, and
(2) a transformer-based language model for proposing
intermediate geometric constructions.
<br><br>

The DD+AR solver (DD = &ldquo;deductive database,&rdquo;
AR = &ldquo;algebraic reasoning&rdquo;)
is essentially a forward-chaining prover augmented with
special geometry domain-specific deduction rules.
The result is that the fixed-point saturation computed
by DD+AR should be larger than the fixed-point of a
more generic fixed-point, as in
<a href="https://github.com/peterhj/meringue">Meringue</a>.
<br><br>

However, DD+AR on its own is not equipped with a method
for choosing intermediate geometric constructions;
DD+AR usually must be paired with the geometry-tuned
language model.
Thus, on many olympiad-level problems, DD+AR alone may
halt with failure because a successful proof requires an
intermediate construction, which DD+AR alone cannot supply.
In other words, DD+AR alone may be said to be
<em>not complete</em>.
<br><br>

On the other hand, the exploration-based improvement
described earlier does serve as a general algorithmic
method that may also be applied to choosing intermediate
geometry constructions.
Forward-chaining with exploration-based improvement
<em>will not halt</em> until the proof goal is found,
or an externally imposed timeout is reached
(or a logical contradiction is uncovered; but such a
scenario requires support from the logic);
in other words, forward-chaining with exploration-based
improvement is <em>complete</em>.
<br><br>

Such an example was found, where forward-chaining with
exploration successfully finds a proof of a hard reduction
of an olympiad-level geometry problem, but DD+AR alone
(without the language model) halts early and thus fails;
please see the discussion of IMO 2009 P2 in the README of
<a href="https://github.com/peterhj/meringue">Meringue</a>.
<br><br>

<h3>Acknowledgments</h3>
<br><br>

We thank David Shin for helpful discussions and feedback.
<br><br>

<h3>References</h3>
<br><br>

<span id="CG00">[CG00]
Shang-Ching Chou, Xiao-Shan Gao, and Jing-Zhong Zhang.
&ldquo;A Deductive Database Approach to Automated Geometry Theorem Proving and Discovering.&rdquo;
<em>Journal of Automated Reasoning</em> 25, pp. 219-246 (2000).
</span>
<br>
<span id="NP12">[NP12]
Hung Q. Ngo, Ely Porat, Christopher R&eacute;, and Atri Rudra.
&ldquo;Worst-case Optimal Join Algorithms.&rdquo;
arXiv preprint <a href="https://arxiv.org/abs/1203.1952v1">1203.1952v1</a> (2012).
</span>
<br>
<span id="TW24">[TW24]
Trieu H. Trinh, Yuhuai Wu, Quoc V. Le, He He, and Thang Luong.
&ldquo;Solving olympiad geometry without human demonstrations.&rdquo;
<em>Nature</em> 625, pp. 476-482 (2024).
</span>
<br>
<span id="V12">[V12]
Todd L. Veldhuizen.
&ldquo;Leapfrog Triejoin: A Simple, Worst-Case Optimal Join Algorithm.&rdquo;
arXiv preprint <a href="https://arxiv.org/abs/1210.0481v5">1210.0481v5</a> (2012).
</span>

</div>
</div><!--#content-->
</div><!--#contentwrap-->
<div id="contentwrapbot"></div>
</div><!--#container-->
</body>
</html>
